# FastAPI ì±—ë´‡ ì„œë²„
# í”„ë¡ íŠ¸ì—”ë“œì—ì„œ í˜¸ì¶œí•˜ëŠ” RAG ì±—ë´‡ API

from fastapi import FastAPI, HTTPException
from fastapi.middleware.cors import CORSMiddleware
from pydantic import BaseModel
from typing import List, Dict, Optional

from openai import OpenAI
from dotenv import load_dotenv
import os
import chromadb
from chromadb.utils import embedding_functions
from pathlib import Path
from sentence_transformers import CrossEncoder
import torch
from torch.nn.functional import sigmoid

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()

# OpenAI í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
api_key = os.getenv('OPENAI_API_KEY')
if not api_key:
    raise ValueError("OPENAI_API_KEYê°€ ì„¤ì •ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

client = OpenAI(api_key=api_key)

# ê²½ë¡œ ì„¤ì •
BASE_DIR = Path(__file__).resolve().parent
CHROMA_DIR = BASE_DIR / "data" / "chromadb_vision"

# Cross-encoder ëª¨ë¸ ì´ˆê¸°í™”
cross_encoder = CrossEncoder('cross-encoder/ms-marco-MiniLM-L-6-v2')

# ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸
SYSTEM_PROMPT = """ë‹¹ì‹ ì€ **ESG(í™˜ê²½Â·ì‚¬íšŒÂ·ì§€ë°°êµ¬ì¡°) ì „ë¬¸ AI ì»¨ì„¤í„´íŠ¸**ì…ë‹ˆë‹¤.
ê¸°ì—…ì˜ ESG ë³´ê³ ì„œë¥¼ ë¶„ì„í•˜ì—¬ ì •í™•í•˜ê³  í†µì°°ë ¥ ìˆëŠ” ë‹µë³€ì„ ì œê³µí•©ë‹ˆë‹¤.

## ğŸ¯ í•µì‹¬ ì›ì¹™

### 1. ì •í™•ì„± (Accuracy)
- **ë°˜ë“œì‹œ** ì œê³µëœ ë¬¸ì„œ ë‚´ìš©ë§Œ ì‚¬ìš©í•˜ì„¸ìš”
- ìˆ˜ì¹˜, ë‚ ì§œ, ê³ ìœ ëª…ì‚¬ëŠ” ë¬¸ì„œ ê·¸ëŒ€ë¡œ ì •í™•íˆ ì¸ìš©í•˜ì„¸ìš”
- ì¶”ì¸¡ì´ë‚˜ ì¼ë°˜ì ì¸ ì§€ì‹ìœ¼ë¡œ ë‹µë³€í•˜ì§€ ë§ˆì„¸ìš”

### 2. ì¶œì²˜ ëª…ì‹œ (Citation)
- ëª¨ë“  ì£¼ìš” ì •ë³´ì— ì¶œì²˜ë¥¼ ëª…ì‹œí•˜ì„¸ìš”
- í˜•ì‹: **(ì¶œì²˜: [íšŒì‚¬ëª…] [ë…„ë„] ESGë³´ê³ ì„œ, p.[í˜ì´ì§€])**
- ì—¬ëŸ¬ ì¶œì²˜ë¥¼ ì¢…í•©í•  ë•ŒëŠ” ê°ê° í‘œì‹œí•˜ì„¸ìš”

### 3. êµ¬ì¡°í™”ëœ ë‹µë³€ (Structure)
- Markdown í˜•ì‹ìœ¼ë¡œ ì²´ê³„ì ìœ¼ë¡œ ì‘ì„±í•˜ì„¸ìš”
- ë³µì¡í•œ ì •ë³´ëŠ” í‘œ, ëª©ë¡, ì†Œì œëª©ì„ í™œìš©í•˜ì„¸ìš”
- í•µì‹¬ ë‚´ìš©ì„ ë¨¼ì € ì œì‹œí•˜ê³  ì„¸ë¶€ì‚¬í•­ì„ ì„¤ëª…í•˜ì„¸ìš”

### 4. ëŒ€í™” ë¬¸ë§¥ (Context)
- ì´ì „ ëŒ€í™” ë‚´ìš©ì„ ì°¸ê³ í•˜ì—¬ ì¼ê´€ì„± ìˆê²Œ ë‹µë³€í•˜ì„¸ìš”
- "ê·¸ê²ƒ", "ì´ì „ì— ë§í•œ" ë“± ëŒ€ëª…ì‚¬ê°€ ê°€ë¦¬í‚¤ëŠ” ë‚´ìš©ì„ ì •í™•íˆ íŒŒì•…í•˜ì„¸ìš”
- ê°™ì€ ì •ë³´ë¥¼ ë°˜ë³µí•˜ì§€ ë§ê³  ìƒˆë¡œìš´ ê´€ì ì„ ì¶”ê°€í•˜ì„¸ìš”

## ğŸ“‹ ë‹µë³€ í˜•ì‹

### ì¼ë°˜ ì§ˆë¬¸:
**[í•µì‹¬ ë‹µë³€]**

[ìƒì„¸ ì„¤ëª…]

ğŸ“Š **ê´€ë ¨ ìˆ˜ì¹˜:**
- í•­ëª©1: ìˆ˜ì¹˜ (ì¶œì²˜)
- í•­ëª©2: ìˆ˜ì¹˜ (ì¶œì²˜)

ğŸ’¡ **ì‹œì‚¬ì :** [ë¶„ì„ ë˜ëŠ” ì˜ë¯¸]

### ì •ë³´ ë¶€ì¡± ì‹œ:
ì œê³µëœ ë¬¸ì„œì—ì„œ í•´ë‹¹ ì •ë³´ë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.

**ê´€ë ¨ ì •ë³´:**
- [ì°¾ì„ ìˆ˜ ìˆëŠ” ìœ ì‚¬ ì •ë³´]

## ğŸ” ESG ë¶„ì•¼ë³„ ì „ë¬¸ì„±

### í™˜ê²½ (Environment)
- íƒ„ì†Œë°°ì¶œëŸ‰ (Scope 1, 2, 3), ì˜¨ì‹¤ê°€ìŠ¤, ì—ë„ˆì§€ ì‚¬ìš©
- ì¬ìƒì—ë„ˆì§€, íê¸°ë¬¼, ìˆ˜ìì›, ìƒë¬¼ë‹¤ì–‘ì„±

### ì‚¬íšŒ (Social)
- ì„ì§ì› (ë‹¤ì–‘ì„±, ì•ˆì „, ë³µì§€, êµìœ¡)
- ê³µê¸‰ë§ ê´€ë¦¬, ì¸ê¶Œ, ì§€ì—­ì‚¬íšŒ ê³µí—Œ

### ì§€ë°°êµ¬ì¡° (Governance)
- ì´ì‚¬íšŒ êµ¬ì„±, ìœ¤ë¦¬ê²½ì˜, ì¤€ë²•ê²½ì˜
- ë¦¬ìŠ¤í¬ ê´€ë¦¬, ì£¼ì£¼ê¶Œë¦¬, ì •ë³´ê³µê°œ

## âš ï¸ ì£¼ì˜ì‚¬í•­
- í™•ì‹¤í•˜ì§€ ì•Šì€ ì •ë³´ëŠ” "ë¬¸ì„œì—ì„œ í™•ì¸ í•„ìš”"ë¼ê³  ëª…ì‹œ
- í•œêµ­ì–´ë¡œ ìì—°ìŠ¤ëŸ½ê³  ì „ë¬¸ì ìœ¼ë¡œ ë‹µë³€í•˜ì„¸ìš”
"""

# FastAPI ì•± ì´ˆê¸°í™”
app = FastAPI(title="ESG RAG Chatbot API", version="1.0.0")

# CORS ì„¤ì • (í”„ë¡ íŠ¸ì—”ë“œ í—ˆìš©)
app.add_middleware(
    CORSMiddleware,
    allow_origins=["*"],  # ëª¨ë“  origin í—ˆìš© (ê°œë°œìš©)
    allow_credentials=True,
    allow_methods=["*"],
    allow_headers=["*"],
)

# ì „ì—­ ë³€ìˆ˜
collection = None


# ìš”ì²­/ì‘ë‹µ ëª¨ë¸
class Message(BaseModel):
    role: str
    content: str


class ChatRequest(BaseModel):
    message: str
    history: Optional[List[Message]] = []


class ChatResponse(BaseModel):
    answer: str
    sources: Optional[List[str]] = []


def initialize_collection():
    """ChromaDB ì»¬ë ‰ì…˜ ì´ˆê¸°í™”"""
    global collection

    print("ğŸ¤– ChromaDB ì´ˆê¸°í™” ì¤‘...")
    chroma_client = chromadb.PersistentClient(path=str(CHROMA_DIR))

    embedding_function = embedding_functions.SentenceTransformerEmbeddingFunction(
        model_name="jhgan/ko-sroberta-multitask"
    )

    collection = chroma_client.get_collection(
        name="esg_vision_collection",
        embedding_function=embedding_function
    )

    doc_count = collection.count()
    print(f"âœ… {doc_count}ê°œ ë¬¸ì„œ ë¡œë“œ ì™„ë£Œ")

    return collection


def rerank_documents(query: str, documents: List[str], metadata_list: List[Dict], top_k: int = 5):
    """Cross-encoderë¥¼ ì‚¬ìš©í•˜ì—¬ ë¬¸ì„œ ì¬ìˆœìœ„í™”"""
    pairs = [[query, doc] for doc in documents]
    raw_scores = cross_encoder.predict(pairs, convert_to_numpy=False)

    if not isinstance(raw_scores, torch.Tensor):
        raw_scores = torch.tensor(raw_scores)
    norm_scores = sigmoid(raw_scores).tolist()

    doc_score_pairs = list(zip(documents, metadata_list, norm_scores))
    doc_score_pairs.sort(key=lambda x: x[2], reverse=True)

    return doc_score_pairs[:top_k]


def search_documents(query: str, initial_k: int = 15, final_k: int = 5):
    """ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰ (2ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰ + Cross-encoder ë¦¬ë­í‚¹)"""
    global collection

    # 1ë‹¨ê³„: ë²¡í„° ê²€ìƒ‰
    results = collection.query(
        query_texts=[query],
        n_results=initial_k
    )

    if not results['documents'][0]:
        return "", []

    # 2ë‹¨ê³„: Cross-encoder ë¦¬ë­í‚¹
    reranked = rerank_documents(
        query,
        results['documents'][0],
        results['metadatas'][0],
        final_k
    )

    # ê²°ê³¼ í¬ë§·íŒ…
    contexts = []
    sources = []

    for doc, metadata, score in reranked:
        company = metadata.get('company', '')
        year = metadata.get('year', '')
        page = metadata.get('page', '')
        version = metadata.get('version', '')

        version_str = f" ({version})" if version else ""
        source = f"{company} {year}ë…„{version_str} ESG ë³´ê³ ì„œ, {page}í˜ì´ì§€"
        sources.append(source)

        # ê´€ë ¨ë„ í‘œì‹œ
        if score > 0.8:
            relevance = "ğŸŒŸ ë§¤ìš° ë†’ìŒ"
        elif score > 0.6:
            relevance = "â­ ë†’ìŒ"
        elif score > 0.4:
            relevance = "âœ¨ ì¤‘ê°„"
        else:
            relevance = "â—‹ ë‚®ìŒ"

        context = f"""
[ì¶œì²˜: {source}] [{relevance}]
{doc[:2000]}...
"""
        contexts.append(context)

    return "\n---\n".join(contexts), sources


def generate_response(query: str, context: str, history: List[Message]):
    """GPT-4oë¡œ ë‹µë³€ ìƒì„±"""

    # ì‹œìŠ¤í…œ í”„ë¡¬í”„íŠ¸ì— ê²€ìƒ‰ëœ ë¬¸ì„œ ì¶”ê°€
    system_with_context = f"""{SYSTEM_PROMPT}

## í˜„ì¬ ì§ˆë¬¸ì— ëŒ€í•œ ê²€ìƒ‰ëœ ë¬¸ì„œ:
{context}
"""

    # ë©”ì‹œì§€ êµ¬ì„±
    messages = [{"role": "system", "content": system_with_context}]

    # ì´ì „ ëŒ€í™” ê¸°ë¡ ì¶”ê°€ (ìµœê·¼ 10ê°œ)
    recent_history = history[-10:] if len(history) > 10 else history
    for msg in recent_history:
        messages.append({"role": msg.role, "content": msg.content})

    # í˜„ì¬ ì§ˆë¬¸ ì¶”ê°€
    messages.append({"role": "user", "content": query})

    response = client.chat.completions.create(
        model="gpt-4o",
        messages=messages,
        temperature=0.3,
        max_tokens=2000
    )

    return response.choices[0].message.content


# API ì—”ë“œí¬ì¸íŠ¸
@app.on_event("startup")
async def startup_event():
    """ì„œë²„ ì‹œì‘ ì‹œ ì´ˆê¸°í™”"""
    initialize_collection()


@app.get("/")
async def root():
    """í—¬ìŠ¤ ì²´í¬"""
    return {"status": "ok", "message": "ESG RAG Chatbot API"}


@app.post("/api/chat", response_model=ChatResponse)
async def chat(request: ChatRequest):
    """ì±—ë´‡ ëŒ€í™” API"""
    global collection

    if collection is None:
        raise HTTPException(status_code=500, detail="ChromaDBê°€ ì´ˆê¸°í™”ë˜ì§€ ì•Šì•˜ìŠµë‹ˆë‹¤.")

    try:
        # 1. ê´€ë ¨ ë¬¸ì„œ ê²€ìƒ‰
        context, sources = search_documents(request.message)

        # 2. ë‹µë³€ ìƒì„±
        answer = generate_response(request.message, context, request.history)

        return ChatResponse(answer=answer, sources=sources)

    except Exception as e:
        raise HTTPException(status_code=500, detail=str(e))


@app.get("/api/health")
async def health_check():
    """ìƒì„¸ í—¬ìŠ¤ ì²´í¬"""
    global collection

    return {
        "status": "ok",
        "chromadb": "connected" if collection else "disconnected",
        "documents": collection.count() if collection else 0
    }


if __name__ == "__main__":
    import uvicorn
    uvicorn.run(app, host="0.0.0.0", port=5000)
